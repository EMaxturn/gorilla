# Base64 Encoding Setup

with open("Screenshot 2025-08-15 at 12.17.54 AM.png", "rb") as img_file:
    img_bytes = img_file.read()

import base64

base64_data = base64.b64encode(img_bytes).decode('utf-8')

mime_type = "image/png"  # change if needed to 'image/jpeg'
data_url = f"data:{mime_type};base64,{base64_data}"

#print("Raw Base64 string:\n", base64_data[:100], "...")  # first 100 chars
#print("\nBase64 URL:\n", data_url[:100], "...")

# Open AI implementation

import base64
from openai import OpenAI

from PIL import Image
from IPython.display import display


client = OpenAI(api_key = 
  
# Function to encode the image
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


# Path to your image
image_path = "Screenshot 2025-08-15 at 12.17.54 AM.png"

# Getting the Base64 string
base64_image = encode_image(image_path)


response = client.responses.create(
    model="gpt-4.1",
    input=[
        {
            "role": "user",
            "content": [
                { "type": "input_text", "text": "what's in this image?" },
                {
                    "type": "input_image",
                    # remember: f"data:image/png if the photo is a png/screenshot
                    # f"data:image/jpeg if image is a jpeg
                    "image_url": f"data:image/png;base64,{base64_image}",
                },
            ],
        }
    ],
)


display(Image.open(image_path))          # shows the original image
print(response.output_text)


# Gemini Inference

import google.generativeai as genai
from google.colab import userdata
from google.colab import userdata


# Access your API key from Colab's secrets manager
GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')

# Configure the generative AI library
genai.configure(api_key=GOOGLE_API_KEY)

from google.genai import types
from google.generativeai import GenerativeModel # Import GenerativeModel

with open('Screenshot 2025-08-15 at 6.05.47 PM.png', 'rb') as f:
      image_bytes = f.read()

# Instantiate the model
# Available models with v1API: https://ai.google.dev/gemini-api/docs/models
model = GenerativeModel('gemini-2.5-pro') # or 2.5-flash, 2.5-flash-lite, etc 

response = model.generate_content(
    contents=[
      {
          'mime_type': 'image/png',
          'data': image_bytes
      },
      'what is going on here' # prompt here
    ]
  )
 
print(response.text)
